apiVersion: opentelemetry.io/v1beta1
kind: OpenTelemetryCollector
metadata:
  name: main
  namespace: monitoring
spec:
  mode: daemonset
  serviceAccount: opentelemetry-collector
  config:
    extensions:
      health_check: {}

    receivers:
      k8s_events:
        namespaces: []

      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317
          http:
            endpoint: 0.0.0.0:4318

      journald:
        directory: /run/log/journal
        # units:
        #   - ssh
        #   - kubelet
        #   - docker
        #   - containerd
        priority: info

      filelog:
        exclude: []
        include:
          - /var/log/pods/*/*/*.log
        include_file_name: false
        include_file_path: true
        operators:
          - id: container-parser
            max_log_size: 102400
            type: container
          # # Find out which format is used by kubernetes
          # - type: router
          #   id: get-format
          #   routes:
          #     - output: parser-docker
          #       expr: 'body matches "^\\{"'
          #     - output: parser-crio
          #       expr: 'body matches "^[^ Z]+ "'
          #     - output: parser-containerd
          #       expr: 'body matches "^[^ Z]+Z"'
          # # Parse CRI-O format
          # - type: regex_parser
          #   id: parser-crio
          #   regex: '^(?P<time>[^ Z]+) (?P<stream>stdout|stderr) (?P<logtag>[^ ]*) ?(?P<log>.*)$'
          #   output: extract_metadata_from_filepath
          #   timestamp:
          #     parse_from: attributes.time
          #     layout_type: gotime
          #     layout: '2006-01-02T15:04:05.999999999Z07:00'
          # # Parse CRI-Containerd format
          # - type: regex_parser
          #   id: parser-containerd
          #   regex: '^(?P<time>[^ ^Z]+Z) (?P<stream>stdout|stderr) (?P<logtag>[^ ]*) ?(?P<log>.*)$'
          #   output: extract_metadata_from_filepath
          #   timestamp:
          #     parse_from: attributes.time
          #     layout: '%Y-%m-%dT%H:%M:%S.%LZ'
          # Parse Docker format
          # - type: json_parser
          #   id: parser-docker
          #   output: extract_metadata_from_filepath
          #   timestamp:
          #     parse_from: attributes.time
          #     layout: '%Y-%m-%dT%H:%M:%S.%LZ'
          # Extract metadata from file path
          # - type: regex_parser
          #   id: extract_metadata_from_filepath
          #   # Pod UID is not always 36 characters long
          #   regex: '^.*\/(?P<namespace>[^_]+)_(?P<pod_name>[^_]+)_(?P<uid>[a-f0-9\-]{16,36})\/(?P<container_name>[^\._]+)\/(?P<restart_count>\d+)\.log$'
          #   parse_from: attributes["log.file.path"]
          #   cache:
          #     size: 128 # default maximum amount of Pods per Node is 110
          # Rename attributes
          # - type: move
          #   from: attributes.log
          #   to: body
          # - type: move
          #   from: attributes.stream
          #   to: attributes["log.iostream"]
          # - type: move
          #   from: attributes.container_name
          #   to: resource["k8s.container.name"]
          # - type: move
          #   from: attributes.namespace
          #   to: resource["k8s.namespace.name"]
          # - type: move
          #   from: attributes.pod_name
          #   to: resource["k8s.pod.name"]
          # - type: move
          #   from: attributes.restart_count
          #   to: resource["k8s.container.restart_count"]
          # - type: move
          #   from: attributes.uid
          #   to: resource["k8s.pod.uid"]
        # retry_on_failure:
        #   enabled: true
        start_at: beginning

      hostmetrics:
        collection_interval: 10s
        root_path: /hostfs
        scrapers:
          cpu:
            metrics:
              system.cpu.utilization:
                enabled: true
          disk: {}
          filesystem:
            exclude_fs_types:
              fs_types:
              - autofs
              - binfmt_misc
              - bpf
              - cgroup2
              - configfs
              - debugfs
              - devpts
              - devtmpfs
              - fusectl
              - hugetlbfs
              - iso9660
              - mqueue
              - nsfs
              - overlay
              - proc
              - procfs
              - pstore
              - rpc_pipefs
              - securityfs
              - selinuxfs
              - squashfs
              - sysfs
              - tracefs
              match_type: strict
            exclude_mount_points:
              match_type: regexp
              mount_points:
              - /dev/*
              - /proc/*
              - /sys/*
              - /run/k3s/containerd/*
              - /var/lib/docker/*
              - /var/lib/kubelet/*
              - /snap/*
            metrics:
              system.filesystem.utilization:
                enabled: true
          load: {}
          memory:
            metrics:
              system.memory.utilization:
                enabled: true
          network: {}

      kubeletstats:
        auth_type: serviceAccount
        collection_interval: 15s
        endpoint: https://${env:OTEL_K8S_NODE_IP}:10250
        extra_metadata_labels:
        - container.id
        - k8s.volume.type
        insecure_skip_verify: true
        k8s_api_config:
          auth_type: serviceAccount
        metric_groups:
        - node
        - pod
        - volume
        - container
        metrics:
          container.cpu.usage:
            enabled: true
          k8s.node.cpu.usage:
            enabled: true
          k8s.node.uptime:
            enabled: true
          k8s.pod.cpu.usage:
            enabled: true
          k8s.pod.uptime:
            enabled: true

      influxdb:
        endpoint: 0.0.0.0:8080

      carbon/receiver_settings:
        endpoint: localhost:8080
        transport: udp

    processors:
      memory_limiter:
        check_interval: 5s
        limit_percentage: 80
        spike_limit_percentage: 25
      k8sattributes:
        extract:
          labels:
          - from: pod
            key: app.kubernetes.io/name
            tag_name: service.name
          - from: pod
            key: k8s-app
            tag_name: service.name
          - from: pod
            key: app.kubernetes.io/instance
            tag_name: k8s.app.instance
          - from: pod
            key: app.kubernetes.io/version
            tag_name: service.version
          - from: pod
            key: app.kubernetes.io/component
            tag_name: k8s.app.component
          metadata:
          - k8s.namespace.name
          - k8s.pod.name
          - k8s.pod.uid
          - k8s.node.name
          - k8s.pod.start_time
          - k8s.deployment.name
          - k8s.replicaset.name
          - k8s.replicaset.uid
          - k8s.daemonset.name
          - k8s.daemonset.uid
          - k8s.job.name
          - k8s.job.uid
          - k8s.container.name
          - k8s.cronjob.name
          - k8s.statefulset.name
          - k8s.statefulset.uid
          - container.image.tag
          - container.image.name
          - k8s.cluster.uid
        filter:
          node_from_env_var: K8S_NODE_NAME
        passthrough: false
        pod_association:
        - sources:
          - from: resource_attribute
            name: k8s.pod.uid
        - sources:
          - from: resource_attribute
            name: k8s.pod.name
          - from: resource_attribute
            name: k8s.namespace.name
          - from: resource_attribute
            name: k8s.node.name
        - sources:
          - from: resource_attribute
            name: k8s.pod.ip
        - sources:
          - from: resource_attribute
            name: k8s.pod.name
          - from: resource_attribute
            name: k8s.namespace.name
        - sources:
          - from: connection
      resourcedetection/env:
        detectors:
        - env
        override: false
        timeout: 2s
      transform:
        error_mode: ignore
        log_statements:
          - context: log
            statements:
              # Parse body as JSON and merge the resulting map with the cache map, ignoring non-json bodies.
              # cache is a field exposed by OTTL that is a temporary storage place for complex operations.
              - merge_maps(cache, ParseJSON(body), "upsert") where IsMatch(body, "^\\{")
      resource:
        attributes:
          - action: insert
            key: loki.resource.labels
            value: service.name, service.namespace, service.version, deployment.environment, k8s.node.name, k8s.pod.ip
      batch:
        send_batch_max_size: 1500
        send_batch_size: 1000
        timeout: 1s

    exporters:
      debug: {}
      otlphttp:
        endpoint: http://loki-write.monitoring.svc.cluster.local:3100/otlp
      clickhouse:
        endpoint: clickhouse://service-clickhouse-main.database-clickhouse.svc.cluster.local:9000?dial_timeout=10s
        username: clickhouse_monitoring_user
        password: ${env:CH_MONITORING_PASSWORD}

        database: otel
        logs_table_name: otel_logs
        traces_table_name: otel_traces

        async_insert: true
        ttl: 0
        compress: lz4
        create_schema: true
        timeout: 5s
        retry_on_failure:
          enabled: true
          initial_interval: 5s
          max_interval: 30s
          max_elapsed_time: 300s

        metrics_tables:
          gauge:
            name: "otel_metrics_gauge"
          sum:
            name: "otel_metrics_sum"
          summary:
            name: "otel_metrics_summary"
          histogram:
            name: "otel_metrics_histogram"
          exponential_histogram:
            name: "otel_metrics_exp_histogram"

        # cluster_name: my_cluster
        # table_engine:
        #   name: ReplicatedMergeTree
        #   params:
    service:
      pipelines:
        traces:
          receivers:
          - otlp
          processors:
          - k8sattributes
          - resourcedetection/env
          - memory_limiter
          - batch
          exporters:
          - debug
          - clickhouse

        metrics:
          receivers:
          - otlp
          - hostmetrics
          - kubeletstats
          - influxdb
          - carbon
          processors:
          - k8sattributes
          - resourcedetection/env
          - memory_limiter
          - batch
          exporters:
          - debug
          - clickhouse

        logs:
          receivers:
          - filelog
          - otlp
          - k8s_events
          processors:
          - k8sattributes
          - resourcedetection/env
          - memory_limiter
          - transform
          - resource
          - batch
          exporters:
          - otlphttp
          - clickhouse

      # telemetry:
      #   metrics:
      #     address: $(OTEL_K8S_POD_IP):8888

  env:
    - name: CH_MONITORING_PASSWORD
      valueFrom:
        secretKeyRef:
          name: clickhouse-main-users
          key: clickhouse_monitoring_password
    - name: OTEL_K8S_NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
    - name: OTEL_K8S_NODE_IP
      valueFrom:
        fieldRef:
          fieldPath: status.hostIP
    - name: OTEL_K8S_NAMESPACE
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: metadata.namespace
    - name: OTEL_K8S_POD_NAME
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: metadata.name
    - name: OTEL_K8S_POD_IP
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: status.podIP
    - name: OTEL_RESOURCE_ATTRIBUTES
      value: "k8s.cluster.name=homelab"

  volumeMounts:
    - name: varlogpods
      mountPath: /var/log/pods
      readOnly: true
    - name: varlibdockercontainers
      mountPath: /var/lib/docker/containers
      readOnly: true
    - name: hostfs
      mountPath: /hostfs
      readOnly: true
      mountPropagation: HostToContainer

  volumes:
    - name: varlogpods
      hostPath:
        path: /var/log/pods
    - name: varlibdockercontainers
      hostPath:
        path: /var/lib/docker/containers
    - name: hostfs
      hostPath:
        path: /
