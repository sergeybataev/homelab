# ---
# # CephFS for applications
# apiVersion: ceph.rook.io/v1
# kind: CephFilesystem
# metadata:
#   name: ceph-fs-archive
#   namespace: rook-ceph
# spec:
#   preservePoolNames: true # Preserve pool names
#   metadataPool:
#     name: cephfs-meta-rep3
#     enableRBDStats: true # Enable RBD stats for monitoring
#     failureDomain: osd
#     replicated:
#       size: 3
#       requireSafeReplicaSize: true # Requires 3 OSDs
#       hybridStorage:
#         primaryDeviceClass: nvme
#         secondaryDeviceClass: hdd
#     parameters:
#       pg_num: "16"
#       pg_num_min: "16"
#   dataPools:
#     - name: app-data-hdd-rep3
#       enableRBDStats: true # Enable RBD stats for monitoring
#       failureDomain: osd
#       replicated:
#         size: 3
#         requireSafeReplicaSize: true
#       parameters:
#         pg_num: "16"
#         pg_num_min: "16"
#       deviceClass: hdd
#   metadataServer:
#     activeCount: 1
#     activeStandby: true
#     resources: # Keep your MDS resources
#       requests: { cpu: "35m", memory: "64M" }
#     # placement: # Keep your MDS placement constraints
#     #   podAntiAffinity:
#     #     requiredDuringSchedulingIgnoredDuringExecution:
#     #       - labelSelector: { matchExpressions: [{ key: app, operator: In, values: [rook-ceph-mds] }] }
#     #         topologyKey: kubernetes.io/hostname
